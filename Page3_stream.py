import pandas 
import folium
import streamlit as st
import matplotlib.pyplot as plt
import plotly.express as px
import pandas as pd
import streamlit as st
from streamlit_folium import st_folium
from streamlit_folium import folium_static
import plotly.graph_objects as go
import geopandas as gpd
from streamlit_folium import folium_static
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, r2_score
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix
import seaborn as sns
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split, RandomizedSearchCV
import shap
import plotly.express as px
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import StratifiedShuffleSplit

# D√©finissez la largeur de la page Streamlit
st.set_page_config(layout="wide")

st.title("üöó La S√©curit√© Routi√®re √† V√©lo : Explorer et Pr√©venir ! üö¥‚Äç‚ôÇÔ∏è")
st.write("Bienvenue sur cette page d√©di√©e √† la s√©curit√© routi√®re, mettant l'accent sur les accidents impliquant des cyclistes. Nous plongeons dans les donn√©es routi√®res depuis 2005 pour comprendre, analyser et am√©liorer la s√©curit√© des cyclistes sur nos routes. Nous allons entra√Æner un mod√®le de machine learning afin d'√©tudier l'impact de diff√©rents facteur sur la gravit√© des accients de v√©lo.")
st.write("üìä Les Donn√©es en Bref : Notre exploration couvre une p√©riode √©tendue, nous permettant de saisir les √©volutions au fil des ann√©es. Ces donn√©es, issues de diff√©rentes sources, sont soigneusement analys√©es pour offrir des perspectives sur les accidents de la route impliquant des cyclistes.")
st.write("üåê Contexte R√©gional : √Ä travers notre analyse, nous explorerons les sp√©cificit√©s r√©gionales, car chaque r√©gion a ses propres caract√©ristiques et d√©fis en mati√®re de s√©curit√© routi√®re.")
st.write("üö® Objectif de cette page : Notre mission est de mieux comprendre les facteurs qui contribuent aux accidents de v√©lo, de pr√©voir les situations √† risque et d'optimiser les mod√®les de pr√©diction pour renforcer la s√©curit√© des cyclistes.")
st.write("Explorez avec nous les mod√®les, les tendances et les r√©sultats qui √©mergent de cette analyse approfondie. Ensemble, travaillons √† rendre nos routes plus s√ªres pour tous !")
st.write("Note : Nous concentrons notre analyse sur les ann√©es √† partir de 2015, offrant ainsi une vision actuelle des enjeux de s√©curit√© routi√®re √† v√©lo.")

# Utilisez pd.read_excel() pour lire le fichier Excel dans un DataFrame
@st.cache_data
def import_data():
    data = pandas.read_csv(r"Base_VO.csv", decimal=".", sep=",")  
    data = data.loc[data['an'] >= 2015]
    # Cr√©er une correspondance d√©partement - r√©gion
    departement_region = {
        1: 'Auvergne-Rh√¥ne-Alpes',
        2: 'Hauts-de-France',
        3: 'Auvergne-Rh√¥ne-Alpes',
        4: 'Provence-Alpes-C√¥te d\'Azur',
        5: 'Provence-Alpes-C√¥te d\'Azur',
        6: 'Provence-Alpes-C√¥te d\'Azur',
        7: 'Auvergne-Rh√¥ne-Alpes',
        8: 'Grand Est',
        9: 'Occitanie',
        10: 'Grand Est',
        11: 'Occitanie',
        12: 'Occitanie',
        13: 'Provence-Alpes-C√¥te d\'Azur',
        14: 'Normandie',
        15: 'Auvergne-Rh√¥ne-Alpes',
        16: 'Nouvelle-Aquitaine',
        17: 'Nouvelle-Aquitaine',
        18: 'Centre-Val de Loire',
        19: 'Nouvelle-Aquitaine',
        21: 'Bourgogne-Franche-Comt√©',
        22: 'Bretagne',
        23: 'Nouvelle-Aquitaine',
        24: 'Nouvelle-Aquitaine',
        25: 'Bourgogne-Franche-Comt√©',
        26: 'Auvergne-Rh√¥ne-Alpes',
        27: 'Normandie',
        28: 'Centre-Val de Loire',
        29: 'Bretagne',
        '2A': 'Corse',
        '2B': 'Corse',
        30: 'Occitanie',
        31: 'Occitanie',
        32: 'Occitanie',
        33: 'Nouvelle-Aquitaine',
        34: 'Occitanie',
        35: 'Bretagne',
        36: 'Centre-Val de Loire',
        37: 'Centre-Val de Loire',
        38: 'Auvergne-Rh√¥ne-Alpes',
        39: 'Bourgogne-Franche-Comt√©',
        40: 'Nouvelle-Aquitaine',
        41: 'Centre-Val de Loire',
        42: 'Auvergne-Rh√¥ne-Alpes',
        43: 'Auvergne-Rh√¥ne-Alpes',
        44: 'Pays de la Loire',
        45: 'Centre-Val de Loire',
        46: 'Occitanie',
        47: 'Nouvelle-Aquitaine',
        48: 'Occitanie',
        49: 'Pays de la Loire',
        50: 'Normandie',
        51: 'Grand Est',
        52: 'Grand Est',
        53: 'Pays de la Loire',
        54: 'Grand Est',
        55: 'Grand Est',
        56: 'Bretagne',
        57: 'Grand Est',
        58: 'Bourgogne-Franche-Comt√©',
        59: 'Hauts-de-France',
        60: 'Hauts-de-France',
        61: 'Normandie',
        62: 'Hauts-de-France',
        63: 'Auvergne-Rh√¥ne-Alpes',
        64: 'Nouvelle-Aquitaine',
        65: 'Occitanie',
        66: 'Occitanie',
        67: 'Grand Est',
        68: 'Grand Est',
        69: 'Auvergne-Rh√¥ne-Alpes',
        70: 'Bourgogne-Franche-Comt√©',
        71: 'Bourgogne-Franche-Comt√©',
        72: 'Pays de la Loire',
        73: 'Auvergne-Rh√¥ne-Alpes',
        74: 'Auvergne-Rh√¥ne-Alpes',
        75: '√éle-de-France',
        76: 'Normandie',
        77: '√éle-de-France',
        78: '√éle-de-France',
        79: 'Nouvelle-Aquitaine',
        80: 'Hauts-de-France',
        81: 'Occitanie',
        82: 'Occitanie',
        83: 'Provence-Alpes-C√¥te d\'Azur',
        84: 'Provence-Alpes-C√¥te d\'Azur',
        85: 'Pays de la Loire',
        86: 'Nouvelle-Aquitaine',
        87: 'Nouvelle-Aquitaine',
        88: 'Grand Est',
        89: 'Bourgogne-Franche-Comt√©',
        90: 'Bourgogne-Franche-Comt√©',
        91: '√éle-de-France',
        92: '√éle-de-France',
        93: '√éle-de-France',
        94: '√éle-de-France',
        95: '√éle-de-France',
        971: 'Guadeloupe',
        972: 'Martinique',
        973: 'Guyane',
        974: 'La R√©union',
        976: 'Mayotte'
    }
    data['region'] = data['dep'].map(departement_region)
    data = data.dropna(subset=['region'])

    region_mapping = {
        'Auvergne-Rh√¥ne-Alpes': 1,
        'Hauts-de-France': 2,
        'Provence-Alpes-C√¥te d\'Azur': 3,
        'Grand Est': 4,
        'Occitanie': 5,
        'Normandie': 6,
        'Centre-Val de Loire': 7,
        'Bourgogne-Franche-Comt√©': 8,
        'Bretagne': 9,
        'Corse': 10,
        'Pays de la Loire': 11,
        'Nouvelle-Aquitaine': 12,
        '√éle-de-France': 13,
        'Guadeloupe': 14,
        'Martinique': 15,
        'Guyane': 16,
        'La R√©union': 17,
        'Mayotte': 18
    }

    # Appliquer la correspondance √† la colonne 'region' de votre DataFrame
    data['region2'] = data['region'].map(region_mapping)
    
    data['grav'] = 0*data['indemne'] + 2*data['blesse_hospi'] + 1*data['hospi_leger'] + 3*data['tue']
    data['equipement'] = data['equipement'].apply(lambda x: eval(x) if isinstance(x, str) else x)

    return data

data = import_data()

# Page de pr√©sentation des mod√®les
def models_presentation():
    @st.cache_data
    def test_model():
        # S√©parer les features et la variable cible
        X = data[["secuexist", "age", "region2", "lum", "atm", "catr", "trajet", "equipement", "homme"]]
        y = data['grav']

        # Imputer les valeurs manquantes
        imputer = SimpleImputer(strategy='most_frequent')
        X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)

        # Diviser les donn√©es en ensembles d'entra√Ænement et de test avec stratification
        X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42, stratify=y)
        models = {
            'Random Forest': RandomForestClassifier(),
            'KNN': KNeighborsClassifier(),
            'XGBoost': XGBClassifier(),
            'SVM': SVC()
        }
        # Cr√©er un DataFrame pour stocker les importances de chaque mod√®le
        importances_df = pd.DataFrame(index=X_imputed.columns)
        # Boucle pour entra√Æner et √©valuer chaque mod√®le
        # Entra√Æner et √©valuer les mod√®les
        results = {}
        class_accuracies = {}
        for model_name, model in models.items():
            model.fit(X_train, y_train.values.ravel())
            y_pred = model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            conf_matrix = confusion_matrix(y_test, y_pred)
            class_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)
            results[model_name] = {'model': model, 'accuracy': accuracy}
            class_accuracies[model_name] = {'class_accuracy': class_accuracy}

        st.write("Affichons les matrices de confusion des diff√©rents mod√®les.")
        st.write("Une matrice de confusion est un moyen de visualiser o√π notre mod√®le a bien fonctionn√© et o√π il a eu des difficult√©s. Cela nous aide √† comprendre comment un mod√®le se comporte dans diff√©rentes situations.")
        # Afficher la matrice de confusion pour chaque mod√®le
        fig, axes = plt.subplots(1, 4, figsize=(18, 4))
        for ax, (model_name, model_conf_matrix) in zip(axes, zip(class_accuracies.keys(), [confusion_matrix(y_test, model.predict(X_test)) for model in models.values()])):
            ax.set_title(f"Matrice de Confusion pour {model_name}")
            total_per_class = model_conf_matrix.sum(axis=1)
            conf_matrix_percentage = (model_conf_matrix.T / total_per_class).T * 100
            sns.heatmap(conf_matrix_percentage, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=ax)
            ax.set_xlabel('Valeurs Pr√©dites')
            ax.set_ylabel('Valeurs R√©elles')

        plt.tight_layout()
        st.pyplot(fig)

        st.write("Lors de l\'observation des matrices de confusion pour chaque mod√®le, il est √©vident que les classes 0 (Indemnes) et 3 (Tu√©s) posent un d√©fi de pr√©diction significatif. Les pourcentages associ√©s √† ces classes sont notablement bas, sugg√©rant que les mod√®les ont du mal √† les identifier correctement. Cette difficult√© peut √™tre attribu√©e √† une repr√©sentation limit√©e de ces classes dans l\'ensemble de donn√©es, ce qui rend la g√©n√©ralisation plus complexe.")
        st.write("En revanche, les classes 1 (Bless√©s L√©gers) et 2 (Bless√©s hospitalis√©s) b√©n√©ficient d'une pr√©diction plus pr√©cise, avec des pourcentages plus √©lev√©s dans les matrices de confusion. Il semble que la repr√©sentation de ces classes soit plus robuste, facilitant ainsi la t√¢che des mod√®les.")
        st.write("En vue de prendre une d√©cision quant au choix du mod√®le, il est n√©cessaire d'examiner les pr√©cisions de chacun d'entre eux.")
        # Vos r√©sultats
        results = {
            "Random Forest": {"model": "RandomForestClassifier()", "accuracy": 0.5714285714285714},
            "KNN": {"model": "KNeighborsClassifier()", "accuracy": 0.5748782467532467},
            "XGBoost": {"model": "XGBClassifier(base_score=None, booster=None, ...)", "accuracy": 0.6288555194805194},
            "SVM": {"model": "SVC()", "accuracy": 0.6057224025974026},
        }

        # Cr√©er un DataFrame √† partir des r√©sultats
        df_results = pd.DataFrame.from_dict(results, orient='index')
        df_results.reset_index(inplace=True)
        df_results.columns = ['Model', 'Model Details', 'Accuracy']

        # Convertir les objets de la colonne "Model Details" en cha√Ænes de texte
        df_results['Model Details'] = df_results['Model Details'].astype(str)

        # Afficher le DataFrame dans Streamlit
        st.dataframe(df_results)

        # Explication sur le choix du mod√®le XGBoost
        st.write("Nous optons pour le mod√®le XGBoost dans notre application en raison de sa pr√©cision sup√©rieure parmi les mod√®les test√©s. Afin de simplifier l'interpr√©tation et d'accro√Ætre la stabilit√© du mod√®le, nous allons regroup√© certaines classes de gravit√©. Les classes 'Indemne' et 'Bless√© L√©ger' ont √©t√© fusionn√©es, de m√™me que les classes 'Bless√© Hospitalis√©' et 'Tu√©'. Nous explorerons √©galement l'importance de chaque variable dans le mod√®le s√©lectionn√©.")

        # Entra√Æner le mod√®le XGBoost
        xgb_model = models['XGBoost']
        xgb_model.fit(X_train, y_train.values.ravel())

        # Obtenir les importances des caract√©ristiques du mod√®le XGBoost
        importances_df['XGBoost'] = xgb_model.feature_importances_

        # Afficher les importances des variables pour le mod√®le choisi (XGBoost)
        chosen_model_importances = importances_df['XGBoost']
        # Afficher un graphique √† barres pour les importances des variables du mod√®le choisi (XGBoost)
        fig1 = px.bar(x=chosen_model_importances.index, y=chosen_model_importances.values, title='Importance des variables explicatives utilis√©es pour le mod√®le XGBoost')
        fig1.update_layout(
            plot_bgcolor="rgba(0,0,0,0)",
            xaxis=dict(showgrid=False, title='Caract√©ristiques'),
            yaxis=dict(showgrid=False, title='Importance')
        )
        st.plotly_chart(fig1, use_container_width=True, figsize=(10, 6))
        st.write("Nous notons que les variables 'R√©gion' (r√©gions fran√ßaises) et 'Catr' (type de route) se d√©marquent comme les plus cruciales dans notre mod√®le XGBoost. Nous pr√©voyons de les maintenir pour la suite de l'analyse.")

    test_model()
    
    st.write("Nous avons choisi d'utiliser un mod√®le XGBoost, en raison de sa capacit√© √† traiter des ensembles de donn√©es complexes et √† fournir des pr√©dictions pr√©cises. Apr√®s l'entra√Ænement initial, nous allons optimis√© les param√®tres du mod√®le pour am√©liorer sa pr√©cision. Pour ce faire, nous allons tester plusieurs combinaisons d'hyperparam√®tres et conserver celle qui maximise la pr√©cision de notre mod√®le (accuracy)")
    
    @st.cache_data
    def xgboost_merged_classes():
        # S√©parer les features et la variable cible
        X = data[['region2', 'catr', "homme"]]
        y = data['grav']

        # Fusionner les classes 0 et 1 en une seule classe (classe 0)
        # Fusionner les classes 2 et 3 en une seule classe (classe 1)
        y_merged = y.replace({0: 0, 1: 0, 2: 1, 3: 1})

        # Diviser les donn√©es en ensembles d'entra√Ænement et de test avec stratification
        X_train, X_test, y_train, y_test = train_test_split(X, y_merged, test_size=0.2, random_state=42, stratify=y_merged)

        # D√©finir les hyperparam√®tres √† optimiser
        param_dist = {
            'learning_rate': [0.01, 0.1, 0.2],
            'n_estimators': [50, 100, 200],
            'max_depth': [3, 5, 7],
            'subsample': [0.8, 0.9, 1.0],
            'colsample_bytree': [0.8, 0.9, 1.0],
            'gamma': [0, 1, 2],
            'min_child_weight': [1, 2, 3],
            'lambda': [0, 1, 2],
            'alpha': [0, 1, 2]
        }

        # Cr√©er le mod√®le XGBoost
        xgb = XGBClassifier()

        # Effectuer une recherche al√©atoire des hyperparam√®tres
        random_search = RandomizedSearchCV(xgb, param_distributions=param_dist, n_iter=10, scoring='accuracy', cv=3, random_state=42)
        random_search.fit(X_train, y_train)

        # Afficher les meilleurs hyperparam√®tres
        best_params = random_search.best_params_
        st.write("Voici la meilleurs combinaison d'hyperparam√®tres :", best_params)

        # Utiliser le mod√®le avec les meilleurs hyperparam√®tres pour pr√©dire sur les donn√©es de test
        y_pred = random_search.best_estimator_.predict(X_test)

        # Calculer et afficher l'accuracy
        accuracy = accuracy_score(y_test, y_pred)
        st.write("Avec cette combinaison d'hyperparam√®tres, nous obtenons l'accuracy suivante : ")
        st.write(accuracy)
        st.write("Nous constatons que la pr√©cision de notre mod√®le XGBoost, une fois optimis√©e, a augment√© de 10 points par rapport √† la version non optimis√©e. Ainsi, nous atteignons d√©sormais une pr√©cision d'environ 73%, ce qui se traduit par la capacit√© du mod√®le √† correctement classer 73 individus sur 100.")
        st.write("Afin de confirmer notre choix, int√©ressons nous √† la matrice de confusion :")

        # Afficher la matrice de confusion
        conf_matrix = confusion_matrix(y_test, y_pred)
        # Affichage de la matrice de confusion sous forme de heatmap
        total_per_class = conf_matrix.sum(axis=1)
        conf_matrix_percentage = (conf_matrix.T / total_per_class).T * 100
        # R√©duire la taille de la figure
        fig, ax = plt.subplots(figsize=(3, 2))
        sns.heatmap(conf_matrix_percentage, annot=True, fmt='.2f', cmap='Blues', cbar=False, ax=ax)
        ax.set_xlabel('Valeurs Pr√©dites')
        ax.set_ylabel('Valeurs R√©elles')
        st.pyplot(fig)
        st.write("Le choix de notre mod√®le s'est av√©r√© judicieux, comme le d√©montre la matrice de confusion. Cette derni√®re offre une visualisation claire de la performance du mod√®le en mettant en √©vidence un grand nombre de pr√©dictions correctes et un nombre limit√© d'erreurs de pr√©diction. Les r√©sultats indiquent une capacit√© significative du mod√®le √† bien classifier les diff√©rentes classes de gravit√© des accidents de v√©lo. Nous observons une pr√©pond√©rance de pr√©dictions pr√©cises, illustrant ainsi la robustesse et la fiabilit√© de notre approche.")
    xgboost_merged_classes()

# Page d'analyse interactive
def interactive_analysis():        
    # Liste des r√©gions fran√ßaises m√©tropolitaines
    regions_francaises = [
        'Auvergne-Rh√¥ne-Alpes',
        'Bourgogne-Franche-Comt√©',
        'Bretagne',
        'Centre-Val de Loire',
        'Corse',
        'Grand Est',
        'Hauts-de-France',
        '√éle-de-France',
        'Normandie',
        'Nouvelle-Aquitaine',
        'Occitanie',
        'Pays de la Loire',
        'Provence-Alpes-C√¥te d\'Azur',
        'Guadeloupe',
        'Martinique',
        'Guyane',
        'La R√©union',
        'Mayotte'
    ]

    # Section pour la s√©lection de la r√©gion
    st.header('S√©lectionnez une r√©gion:')
    selected_region = st.selectbox('Choisissez une r√©gion:', regions_francaises)

    # Section pour la s√©lection du sexe et de l'√¢ge
    st.header('S√©lectionnez le sexe et l\'√¢ge:')
    gender_options = ['Masculin', 'F√©minin']
    selected_gender = st.radio('Choisissez le sexe:', gender_options)

    # Affichage des r√©sultats
    st.write('Vous avez choisi la r√©gion:', selected_region)
    st.write('Vous avez choisi le sexe:', selected_gender)

    boutton_test = st.button("R√©sultat avec mes donn√©es personnelles")

    if boutton_test :
        st.write("coucou")

interactive_analysis()

# Ajoutez un espace dans la barre lat√©rale
st.sidebar.write("Et pour les curieux :")

# Bouton dans la barre lat√©rale
button_clicked = st.sidebar.button("Comprenez notre mod√®le")

# Si le bouton est cliqu√©, affichez le contenu de la page sp√©cifique
if button_clicked:
    st.title("Comprenons ensemble le mod√®le utilis√© et l'optimisation de celui-ci !")
    st.header("Objectif du Mod√®le : ")
    st.write("Le mod√®le que nous avons d√©velopp√© a pour objectif de pr√©dire la gravit√© des accidents de v√©lo en se basant sur divers facteurs. La gravit√© des accidents est class√©e en quatre cat√©gories : indemne, bless√© l√©ger, bless√© hospitalis√©, et tu√©. Comprendre la gravit√© des accidents peut nous aider √† identifier les principaux contributeurs aux incidents graves, ce qui √† son tour peut informer des mesures de s√©curit√© cibl√©es pour r√©duire les risques sur nos routes.")
    st.header("Variables Utilis√©es : ")
    st.write(" - Securit√© Existante (secuexist) : Repr√©sente les √©quipements de s√©curit√© port√©s par les individus impliqu√©s dans l'accident (casque, ceinture, etc.).")
    st.write("- √Çge (age) : L'√¢ge des personnes impliqu√©es dans l'accident.")
    st.write("- R√©gion (region) : La r√©gion g√©ographique o√π l'accident s'est produit. Chaque r√©gion a ses propres caract√©ristiques et d√©fis en mati√®re de s√©curit√© routi√®re.")
    st.write("- Luminosit√© (lum) : Les conditions d'√©clairage au moment de l'accident.")
    st.write("- Atmosph√®re (atm) : Les conditions atmosph√©riques au moment de l'accident.")
    st.write("- Type de Route (catr) : La cat√©gorie de route o√π l'accident s'est produit.")
    st.write("- Type de Trajet (trajet) : Le type de trajet effectu√© par les individus (domicile-travail, domicile-√©cole, etc.).")
    st.write("- √âquipement (equipement) : Les √©quipements sp√©cifiques utilis√©s lors de l'accident.")
    st.write("- Homme (sexe) : Genre de l'individu accident√©.")
    st.header("Observons les r√©sultats des diff√©rents mod√®les test√©s (KNN, SVM, Random Forest et XGBoost)")
    # Display the content of models presentation
    models_presentation()
